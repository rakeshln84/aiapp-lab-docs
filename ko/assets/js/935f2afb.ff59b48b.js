"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[696],{5988:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"\ud658\uc601\ud569\ub2c8\ub2e4","href":"/aiapp-lab-docs/ko/","docId":"Welcome","unlisted":false},{"type":"link","label":"\uc2dc\uc791\ud558\uae30","href":"/aiapp-lab-docs/ko/setup","docId":"Get-Started","unlisted":false},{"type":"category","label":" 1\ubd80 - \uc6cc\ud06c\uc0f5","collapsible":true,"collapsed":false,"className":"red","items":[{"type":"link","label":"Basic Prompting","href":"/aiapp-lab-docs/ko/Part-1-labs/Basic-Prompting","docId":"Part-1-labs/Basic-Prompting","unlisted":false},{"type":"link","label":"Prompt engineering techniques","href":"/aiapp-lab-docs/ko/Part-1-labs/Prompt-engineering-techniques","docId":"Part-1-labs/Prompt-engineering-techniques","unlisted":false}]},{"type":"category","label":" 2\ubd80 - \uc6cc\ud06c\uc0f5","collapsible":true,"collapsed":false,"className":"red","items":[{"type":"link","label":"System Message","href":"/aiapp-lab-docs/ko/Part-2-labs/System-Message","docId":"Part-2-labs/System-Message","unlisted":false},{"type":"link","label":"Add knowledge","href":"/aiapp-lab-docs/ko/Part-2-labs/Add-Knowledge","docId":"Part-2-labs/Add-Knowledge","unlisted":false},{"type":"link","label":"Function Calling","href":"/aiapp-lab-docs/ko/Part-2-labs/Function-Calling","docId":"Part-2-labs/Function-Calling","unlisted":false}]},{"type":"category","label":"\uac1c\ub150 \ubc0f \ub9ac\uc18c\uc2a4","collapsible":true,"collapsed":true,"className":"red","items":[{"type":"link","label":"AI Models & Deployments","href":"/aiapp-lab-docs/ko/ai-models","docId":"Concepts/Explore-Models","unlisted":false},{"type":"link","label":"Large Language Model (LLM)","href":"/aiapp-lab-docs/ko/llms","docId":"Concepts/Understand-LLMs","unlisted":false},{"type":"link","label":"At home","href":"/aiapp-lab-docs/ko/at-home","docId":"Concepts/At-home","unlisted":false},{"type":"link","label":"Tokenization","href":"/aiapp-lab-docs/ko/tokenization","docId":"Concepts/Understand-Tokens","unlisted":false}]},{"type":"link","label":"\uc694\uc57d","href":"/aiapp-lab-docs/ko/summary","docId":"Summary","unlisted":false}]},"docs":{"Concepts/At-home":{"id":"Concepts/At-home","title":"At home","description":"At home","sidebar":"tutorialSidebar"},"Concepts/Explore-Models":{"id":"Concepts/Explore-Models","title":"AI Models & Deployments","description":"What is an AI Model?","sidebar":"tutorialSidebar"},"Concepts/Understand-LLMs":{"id":"Concepts/Understand-LLMs","title":"Large Language Model (LLM)","description":"A large language model (LLM) is a type of AI that can process and produce natural language text. It learns from a massive amount of text data such as books, articles, and web pages to discover patterns and rules of language from them.","sidebar":"tutorialSidebar"},"Concepts/Understand-Tokens":{"id":"Concepts/Understand-Tokens","title":"Tokenization","description":"We\'ve mentioned \\"tokens\\" a few times in previous lessons, but we didn\'t explain what those were and why they matter. Let\'s discuss that now.","sidebar":"tutorialSidebar"},"Get-Started":{"id":"Get-Started","title":"\uc2dc\uc791\ud558\uae30","description":"\uc774 \ud398\uc774\uc9c0\ub294 \uae30\uacc4 \ubc88\uc5ed\uc744 \ud1b5\ud574 \ud55c\uad6d\uc5b4\ub85c \ubc88\uc5ed\ud588\uc2b5\ub2c8\ub2e4. \uc5b4\uc0c9\ud55c \ud45c\ud604\uc774 \uc788\uc744 \uc218 \uc788\uc73c\ub2c8 \uc591\ud574 \ubc14\ub78d\ub2c8\ub2e4.","sidebar":"tutorialSidebar"},"Part-1-labs/Basic-Prompting":{"id":"Part-1-labs/Basic-Prompting","title":"Basic Prompting","description":"Prompt engineering is a concept in Natural Language Processing (NLP) that involves embedding descriptions of tasks in input to prompt the model to output the desired results.","sidebar":"tutorialSidebar"},"Part-1-labs/Prompt-engineering-techniques":{"id":"Part-1-labs/Prompt-engineering-techniques","title":"Prompt engineering techniques","description":"OpenAI models like GPT-3 do not learn or adapt during user interactions. They generate responses based on pre-training with a large dataset and do not update their knowledge from individual conversations. Any improvements or updates to the model\'s capabilities are made through a controlled retraining process by OpenAI, not through real-time learning.","sidebar":"tutorialSidebar"},"Part-2-labs/Add-Knowledge":{"id":"Part-2-labs/Add-Knowledge","title":"Add knowledge","description":"Retrieval-Augmented Generation (RAG) is an AI technique that retrieves relevant information from a database and then uses it to help generate more informed and contextually accurate text responses.","sidebar":"tutorialSidebar"},"Part-2-labs/Function-Calling":{"id":"Part-2-labs/Function-Calling","title":"Function Calling","description":"GPT-3.5 and GPT-4 models can take user-defined functions as input and generate structured output.","sidebar":"tutorialSidebar"},"Part-2-labs/System-Message":{"id":"Part-2-labs/System-Message","title":"System Message","description":"The system message is used to communicate instructions or provide context to the model at the beginning of a conversation.","sidebar":"tutorialSidebar"},"Summary":{"id":"Summary","title":"\uc694\uc57d","description":"\uc774 \ud398\uc774\uc9c0\ub294 \uae30\uacc4 \ubc88\uc5ed\uc744 \ud1b5\ud574 \ud55c\uad6d\uc5b4\ub85c \ubc88\uc5ed\ud588\uc2b5\ub2c8\ub2e4. \uc5b4\uc0c9\ud55c \ud45c\ud604\uc774 \uc788\uc744 \uc218 \uc788\uc73c\ub2c8 \uc591\ud574 \ubc14\ub78d\ub2c8\ub2e4.","sidebar":"tutorialSidebar"},"Welcome":{"id":"Welcome","title":"\ud658\uc601\ud569\ub2c8\ub2e4","description":"\uc774 \ud398\uc774\uc9c0\ub294 \uae30\uacc4 \ubc88\uc5ed\uc744 \ud1b5\ud574 \ud55c\uad6d\uc5b4\ub85c \ubc88\uc5ed\ud588\uc2b5\ub2c8\ub2e4. \uc5b4\uc0c9\ud55c \ud45c\ud604\uc774 \uc788\uc744 \uc218 \uc788\uc73c\ub2c8 \uc591\ud574 \ubc14\ub78d\ub2c8\ub2e4.","sidebar":"tutorialSidebar"}}}')}}]);